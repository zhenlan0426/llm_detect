{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import sys\nsys.path.insert(0,'/kaggle/input/llm-packages')\nbatch_size = 6\nTARGET_MODEL = \"/kaggle/input/mistral-7b-v0-1/Mistral-7B-v0.1\"\n\ndevice = 'cuda'\nDEBUG = False","metadata":{"execution":{"iopub.status.busy":"2023-11-10T18:56:10.437945Z","iopub.execute_input":"2023-11-10T18:56:10.438178Z","iopub.status.idle":"2023-11-10T18:56:10.448530Z","shell.execute_reply.started":"2023-11-10T18:56:10.438155Z","shell.execute_reply":"2023-11-10T18:56:10.447719Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom functools import partial\nINPUT_DIR = \"../input/\"\ntest_df = pd.read_csv(INPUT_DIR + \"llm-detect-ai-generated-text/test_essays.csv\", sep=',')","metadata":{"execution":{"iopub.status.busy":"2023-11-10T18:56:10.449983Z","iopub.execute_input":"2023-11-10T18:56:10.450298Z","iopub.status.idle":"2023-11-10T18:56:10.824818Z","shell.execute_reply.started":"2023-11-10T18:56:10.450252Z","shell.execute_reply":"2023-11-10T18:56:10.823678Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"test_df.shape: (3, 3)\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install -q -U accelerate --no-index --find-links ../input/llm-detect-pip/\n!pip install -q -U bitsandbytes --no-index --find-links ../input/llm-detect-pip/","metadata":{"execution":{"iopub.status.busy":"2023-11-10T18:56:10.826536Z","iopub.execute_input":"2023-11-10T18:56:10.826884Z","iopub.status.idle":"2023-11-10T18:56:37.852997Z","shell.execute_reply.started":"2023-11-10T18:56:10.826847Z","shell.execute_reply":"2023-11-10T18:56:37.851927Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"from transformers import AutoTokenizer, MistralForSequenceClassification\nfrom llm_util import *\ntokenizer = AutoTokenizer.from_pretrained(TARGET_MODEL)\ntokenizer.pad_token = tokenizer.eos_token","metadata":{"execution":{"iopub.status.busy":"2023-11-10T18:56:37.855350Z","iopub.execute_input":"2023-11-10T18:56:37.855650Z","iopub.status.idle":"2023-11-10T18:56:43.291732Z","shell.execute_reply.started":"2023-11-10T18:56:37.855622Z","shell.execute_reply":"2023-11-10T18:56:43.290920Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"from transformers import BitsAndBytesConfig\nfrom peft import PeftType,PromptEncoderConfig,get_peft_model\n\nnf4_config = BitsAndBytesConfig(\n   load_in_4bit=True,\n   bnb_4bit_quant_type=\"nf4\",\n   bnb_4bit_use_double_quant=True,\n   bnb_4bit_compute_dtype=torch.bfloat16\n)","metadata":{"execution":{"iopub.status.busy":"2023-11-10T18:56:43.293103Z","iopub.execute_input":"2023-11-10T18:56:43.293670Z","iopub.status.idle":"2023-11-10T18:56:44.122583Z","shell.execute_reply.started":"2023-11-10T18:56:43.293629Z","shell.execute_reply":"2023-11-10T18:56:44.121791Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n","output_type":"stream"}]},{"cell_type":"code","source":"model = MistralForSequenceClassification.from_pretrained(TARGET_MODEL,num_labels=2,quantization_config=nf4_config, \\\n                                                          device_map={\"\":0})\npeft_type = PeftType.P_TUNING\npeft_config = PromptEncoderConfig(task_type=\"SEQ_CLS\", num_virtual_tokens=8, \\\n                                  encoder_hidden_size=4096,encoder_dropout=0.1,\\\n                                  encoder_num_layers=2,encoder_reparameterization_type='MLP')#'LSTM')\nmodel = get_peft_model(model, peft_config)\nmodel.config.pad_token_id = tokenizer.pad_token_id\nmodel.load_state_dict(torch.load('/kaggle/input/llm-model/weights.pth'),strict=False);\nmodel = model.half()","metadata":{"execution":{"iopub.status.busy":"2023-11-10T18:56:44.123664Z","iopub.execute_input":"2023-11-10T18:56:44.123942Z","iopub.status.idle":"2023-11-10T18:59:23.550863Z","shell.execute_reply.started":"2023-11-10T18:56:44.123917Z","shell.execute_reply":"2023-11-10T18:59:23.547438Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":6,"outputs":[{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1fb01026e043422a828c38ef41cd616b"}},"metadata":{}},{"name":"stderr","text":"Some weights of MistralForSequenceClassification were not initialized from the model checkpoint at /kaggle/input/mistral-7b-v0-1/Mistral-7B-v0.1 and are newly initialized: ['score.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"_IncompatibleKeys(missing_keys=['base_model.model.embed_tokens.weight', 'base_model.model.layers.0.self_attn.q_proj.weight', 'base_model.model.layers.0.self_attn.k_proj.weight', 'base_model.model.layers.0.self_attn.v_proj.weight', 'base_model.model.layers.0.self_attn.o_proj.weight', 'base_model.model.layers.0.mlp.gate_proj.weight', 'base_model.model.layers.0.mlp.up_proj.weight', 'base_model.model.layers.0.mlp.down_proj.weight', 'base_model.model.layers.0.input_layernorm.weight', 'base_model.model.layers.0.post_attention_layernorm.weight', 'base_model.model.layers.1.self_attn.q_proj.weight', 'base_model.model.layers.1.self_attn.k_proj.weight', 'base_model.model.layers.1.self_attn.v_proj.weight', 'base_model.model.layers.1.self_attn.o_proj.weight', 'base_model.model.layers.1.mlp.gate_proj.weight', 'base_model.model.layers.1.mlp.up_proj.weight', 'base_model.model.layers.1.mlp.down_proj.weight', 'base_model.model.layers.1.input_layernorm.weight', 'base_model.model.layers.1.post_attention_layernorm.weight', 'base_model.model.layers.2.self_attn.q_proj.weight', 'base_model.model.layers.2.self_attn.k_proj.weight', 'base_model.model.layers.2.self_attn.v_proj.weight', 'base_model.model.layers.2.self_attn.o_proj.weight', 'base_model.model.layers.2.mlp.gate_proj.weight', 'base_model.model.layers.2.mlp.up_proj.weight', 'base_model.model.layers.2.mlp.down_proj.weight', 'base_model.model.layers.2.input_layernorm.weight', 'base_model.model.layers.2.post_attention_layernorm.weight', 'base_model.model.layers.3.self_attn.q_proj.weight', 'base_model.model.layers.3.self_attn.k_proj.weight', 'base_model.model.layers.3.self_attn.v_proj.weight', 'base_model.model.layers.3.self_attn.o_proj.weight', 'base_model.model.layers.3.mlp.gate_proj.weight', 'base_model.model.layers.3.mlp.up_proj.weight', 'base_model.model.layers.3.mlp.down_proj.weight', 'base_model.model.layers.3.input_layernorm.weight', 'base_model.model.layers.3.post_attention_layernorm.weight', 'base_model.model.layers.4.self_attn.q_proj.weight', 'base_model.model.layers.4.self_attn.k_proj.weight', 'base_model.model.layers.4.self_attn.v_proj.weight', 'base_model.model.layers.4.self_attn.o_proj.weight', 'base_model.model.layers.4.mlp.gate_proj.weight', 'base_model.model.layers.4.mlp.up_proj.weight', 'base_model.model.layers.4.mlp.down_proj.weight', 'base_model.model.layers.4.input_layernorm.weight', 'base_model.model.layers.4.post_attention_layernorm.weight', 'base_model.model.layers.5.self_attn.q_proj.weight', 'base_model.model.layers.5.self_attn.k_proj.weight', 'base_model.model.layers.5.self_attn.v_proj.weight', 'base_model.model.layers.5.self_attn.o_proj.weight', 'base_model.model.layers.5.mlp.gate_proj.weight', 'base_model.model.layers.5.mlp.up_proj.weight', 'base_model.model.layers.5.mlp.down_proj.weight', 'base_model.model.layers.5.input_layernorm.weight', 'base_model.model.layers.5.post_attention_layernorm.weight', 'base_model.model.layers.6.self_attn.q_proj.weight', 'base_model.model.layers.6.self_attn.k_proj.weight', 'base_model.model.layers.6.self_attn.v_proj.weight', 'base_model.model.layers.6.self_attn.o_proj.weight', 'base_model.model.layers.6.mlp.gate_proj.weight', 'base_model.model.layers.6.mlp.up_proj.weight', 'base_model.model.layers.6.mlp.down_proj.weight', 'base_model.model.layers.6.input_layernorm.weight', 'base_model.model.layers.6.post_attention_layernorm.weight', 'base_model.model.layers.7.self_attn.q_proj.weight', 'base_model.model.layers.7.self_attn.k_proj.weight', 'base_model.model.layers.7.self_attn.v_proj.weight', 'base_model.model.layers.7.self_attn.o_proj.weight', 'base_model.model.layers.7.mlp.gate_proj.weight', 'base_model.model.layers.7.mlp.up_proj.weight', 'base_model.model.layers.7.mlp.down_proj.weight', 'base_model.model.layers.7.input_layernorm.weight', 'base_model.model.layers.7.post_attention_layernorm.weight', 'base_model.model.layers.8.self_attn.q_proj.weight', 'base_model.model.layers.8.self_attn.k_proj.weight', 'base_model.model.layers.8.self_attn.v_proj.weight', 'base_model.model.layers.8.self_attn.o_proj.weight', 'base_model.model.layers.8.mlp.gate_proj.weight', 'base_model.model.layers.8.mlp.up_proj.weight', 'base_model.model.layers.8.mlp.down_proj.weight', 'base_model.model.layers.8.input_layernorm.weight', 'base_model.model.layers.8.post_attention_layernorm.weight', 'base_model.model.layers.9.self_attn.q_proj.weight', 'base_model.model.layers.9.self_attn.k_proj.weight', 'base_model.model.layers.9.self_attn.v_proj.weight', 'base_model.model.layers.9.self_attn.o_proj.weight', 'base_model.model.layers.9.mlp.gate_proj.weight', 'base_model.model.layers.9.mlp.up_proj.weight', 'base_model.model.layers.9.mlp.down_proj.weight', 'base_model.model.layers.9.input_layernorm.weight', 'base_model.model.layers.9.post_attention_layernorm.weight', 'base_model.model.layers.10.self_attn.q_proj.weight', 'base_model.model.layers.10.self_attn.k_proj.weight', 'base_model.model.layers.10.self_attn.v_proj.weight', 'base_model.model.layers.10.self_attn.o_proj.weight', 'base_model.model.layers.10.mlp.gate_proj.weight', 'base_model.model.layers.10.mlp.up_proj.weight', 'base_model.model.layers.10.mlp.down_proj.weight', 'base_model.model.layers.10.input_layernorm.weight', 'base_model.model.layers.10.post_attention_layernorm.weight', 'base_model.model.layers.11.self_attn.q_proj.weight', 'base_model.model.layers.11.self_attn.k_proj.weight', 'base_model.model.layers.11.self_attn.v_proj.weight', 'base_model.model.layers.11.self_attn.o_proj.weight', 'base_model.model.layers.11.mlp.gate_proj.weight', 'base_model.model.layers.11.mlp.up_proj.weight', 'base_model.model.layers.11.mlp.down_proj.weight', 'base_model.model.layers.11.input_layernorm.weight', 'base_model.model.layers.11.post_attention_layernorm.weight', 'base_model.model.layers.12.self_attn.q_proj.weight', 'base_model.model.layers.12.self_attn.k_proj.weight', 'base_model.model.layers.12.self_attn.v_proj.weight', 'base_model.model.layers.12.self_attn.o_proj.weight', 'base_model.model.layers.12.mlp.gate_proj.weight', 'base_model.model.layers.12.mlp.up_proj.weight', 'base_model.model.layers.12.mlp.down_proj.weight', 'base_model.model.layers.12.input_layernorm.weight', 'base_model.model.layers.12.post_attention_layernorm.weight', 'base_model.model.layers.13.self_attn.q_proj.weight', 'base_model.model.layers.13.self_attn.k_proj.weight', 'base_model.model.layers.13.self_attn.v_proj.weight', 'base_model.model.layers.13.self_attn.o_proj.weight', 'base_model.model.layers.13.mlp.gate_proj.weight', 'base_model.model.layers.13.mlp.up_proj.weight', 'base_model.model.layers.13.mlp.down_proj.weight', 'base_model.model.layers.13.input_layernorm.weight', 'base_model.model.layers.13.post_attention_layernorm.weight', 'base_model.model.layers.14.self_attn.q_proj.weight', 'base_model.model.layers.14.self_attn.k_proj.weight', 'base_model.model.layers.14.self_attn.v_proj.weight', 'base_model.model.layers.14.self_attn.o_proj.weight', 'base_model.model.layers.14.mlp.gate_proj.weight', 'base_model.model.layers.14.mlp.up_proj.weight', 'base_model.model.layers.14.mlp.down_proj.weight', 'base_model.model.layers.14.input_layernorm.weight', 'base_model.model.layers.14.post_attention_layernorm.weight', 'base_model.model.layers.15.self_attn.q_proj.weight', 'base_model.model.layers.15.self_attn.k_proj.weight', 'base_model.model.layers.15.self_attn.v_proj.weight', 'base_model.model.layers.15.self_attn.o_proj.weight', 'base_model.model.layers.15.mlp.gate_proj.weight', 'base_model.model.layers.15.mlp.up_proj.weight', 'base_model.model.layers.15.mlp.down_proj.weight', 'base_model.model.layers.15.input_layernorm.weight', 'base_model.model.layers.15.post_attention_layernorm.weight', 'base_model.model.layers.16.self_attn.q_proj.weight', 'base_model.model.layers.16.self_attn.k_proj.weight', 'base_model.model.layers.16.self_attn.v_proj.weight', 'base_model.model.layers.16.self_attn.o_proj.weight', 'base_model.model.layers.16.mlp.gate_proj.weight', 'base_model.model.layers.16.mlp.up_proj.weight', 'base_model.model.layers.16.mlp.down_proj.weight', 'base_model.model.layers.16.input_layernorm.weight', 'base_model.model.layers.16.post_attention_layernorm.weight', 'base_model.model.layers.17.self_attn.q_proj.weight', 'base_model.model.layers.17.self_attn.k_proj.weight', 'base_model.model.layers.17.self_attn.v_proj.weight', 'base_model.model.layers.17.self_attn.o_proj.weight', 'base_model.model.layers.17.mlp.gate_proj.weight', 'base_model.model.layers.17.mlp.up_proj.weight', 'base_model.model.layers.17.mlp.down_proj.weight', 'base_model.model.layers.17.input_layernorm.weight', 'base_model.model.layers.17.post_attention_layernorm.weight', 'base_model.model.layers.18.self_attn.q_proj.weight', 'base_model.model.layers.18.self_attn.k_proj.weight', 'base_model.model.layers.18.self_attn.v_proj.weight', 'base_model.model.layers.18.self_attn.o_proj.weight', 'base_model.model.layers.18.mlp.gate_proj.weight', 'base_model.model.layers.18.mlp.up_proj.weight', 'base_model.model.layers.18.mlp.down_proj.weight', 'base_model.model.layers.18.input_layernorm.weight', 'base_model.model.layers.18.post_attention_layernorm.weight', 'base_model.model.layers.19.self_attn.q_proj.weight', 'base_model.model.layers.19.self_attn.k_proj.weight', 'base_model.model.layers.19.self_attn.v_proj.weight', 'base_model.model.layers.19.self_attn.o_proj.weight', 'base_model.model.layers.19.mlp.gate_proj.weight', 'base_model.model.layers.19.mlp.up_proj.weight', 'base_model.model.layers.19.mlp.down_proj.weight', 'base_model.model.layers.19.input_layernorm.weight', 'base_model.model.layers.19.post_attention_layernorm.weight', 'base_model.model.layers.20.self_attn.q_proj.weight', 'base_model.model.layers.20.self_attn.k_proj.weight', 'base_model.model.layers.20.self_attn.v_proj.weight', 'base_model.model.layers.20.self_attn.o_proj.weight', 'base_model.model.layers.20.mlp.gate_proj.weight', 'base_model.model.layers.20.mlp.up_proj.weight', 'base_model.model.layers.20.mlp.down_proj.weight', 'base_model.model.layers.20.input_layernorm.weight', 'base_model.model.layers.20.post_attention_layernorm.weight', 'base_model.model.layers.21.self_attn.q_proj.weight', 'base_model.model.layers.21.self_attn.k_proj.weight', 'base_model.model.layers.21.self_attn.v_proj.weight', 'base_model.model.layers.21.self_attn.o_proj.weight', 'base_model.model.layers.21.mlp.gate_proj.weight', 'base_model.model.layers.21.mlp.up_proj.weight', 'base_model.model.layers.21.mlp.down_proj.weight', 'base_model.model.layers.21.input_layernorm.weight', 'base_model.model.layers.21.post_attention_layernorm.weight', 'base_model.model.layers.22.self_attn.q_proj.weight', 'base_model.model.layers.22.self_attn.k_proj.weight', 'base_model.model.layers.22.self_attn.v_proj.weight', 'base_model.model.layers.22.self_attn.o_proj.weight', 'base_model.model.layers.22.mlp.gate_proj.weight', 'base_model.model.layers.22.mlp.up_proj.weight', 'base_model.model.layers.22.mlp.down_proj.weight', 'base_model.model.layers.22.input_layernorm.weight', 'base_model.model.layers.22.post_attention_layernorm.weight', 'base_model.model.layers.23.self_attn.q_proj.weight', 'base_model.model.layers.23.self_attn.k_proj.weight', 'base_model.model.layers.23.self_attn.v_proj.weight', 'base_model.model.layers.23.self_attn.o_proj.weight', 'base_model.model.layers.23.mlp.gate_proj.weight', 'base_model.model.layers.23.mlp.up_proj.weight', 'base_model.model.layers.23.mlp.down_proj.weight', 'base_model.model.layers.23.input_layernorm.weight', 'base_model.model.layers.23.post_attention_layernorm.weight', 'base_model.model.layers.24.self_attn.q_proj.weight', 'base_model.model.layers.24.self_attn.k_proj.weight', 'base_model.model.layers.24.self_attn.v_proj.weight', 'base_model.model.layers.24.self_attn.o_proj.weight', 'base_model.model.layers.24.mlp.gate_proj.weight', 'base_model.model.layers.24.mlp.up_proj.weight', 'base_model.model.layers.24.mlp.down_proj.weight', 'base_model.model.layers.24.input_layernorm.weight', 'base_model.model.layers.24.post_attention_layernorm.weight', 'base_model.model.layers.25.self_attn.q_proj.weight', 'base_model.model.layers.25.self_attn.k_proj.weight', 'base_model.model.layers.25.self_attn.v_proj.weight', 'base_model.model.layers.25.self_attn.o_proj.weight', 'base_model.model.layers.25.mlp.gate_proj.weight', 'base_model.model.layers.25.mlp.up_proj.weight', 'base_model.model.layers.25.mlp.down_proj.weight', 'base_model.model.layers.25.input_layernorm.weight', 'base_model.model.layers.25.post_attention_layernorm.weight', 'base_model.model.layers.26.self_attn.q_proj.weight', 'base_model.model.layers.26.self_attn.k_proj.weight', 'base_model.model.layers.26.self_attn.v_proj.weight', 'base_model.model.layers.26.self_attn.o_proj.weight', 'base_model.model.layers.26.mlp.gate_proj.weight', 'base_model.model.layers.26.mlp.up_proj.weight', 'base_model.model.layers.26.mlp.down_proj.weight', 'base_model.model.layers.26.input_layernorm.weight', 'base_model.model.layers.26.post_attention_layernorm.weight', 'base_model.model.layers.27.self_attn.q_proj.weight', 'base_model.model.layers.27.self_attn.k_proj.weight', 'base_model.model.layers.27.self_attn.v_proj.weight', 'base_model.model.layers.27.self_attn.o_proj.weight', 'base_model.model.layers.27.mlp.gate_proj.weight', 'base_model.model.layers.27.mlp.up_proj.weight', 'base_model.model.layers.27.mlp.down_proj.weight', 'base_model.model.layers.27.input_layernorm.weight', 'base_model.model.layers.27.post_attention_layernorm.weight', 'base_model.model.layers.28.self_attn.q_proj.weight', 'base_model.model.layers.28.self_attn.k_proj.weight', 'base_model.model.layers.28.self_attn.v_proj.weight', 'base_model.model.layers.28.self_attn.o_proj.weight', 'base_model.model.layers.28.mlp.gate_proj.weight', 'base_model.model.layers.28.mlp.up_proj.weight', 'base_model.model.layers.28.mlp.down_proj.weight', 'base_model.model.layers.28.input_layernorm.weight', 'base_model.model.layers.28.post_attention_layernorm.weight', 'base_model.model.layers.29.self_attn.q_proj.weight', 'base_model.model.layers.29.self_attn.k_proj.weight', 'base_model.model.layers.29.self_attn.v_proj.weight', 'base_model.model.layers.29.self_attn.o_proj.weight', 'base_model.model.layers.29.mlp.gate_proj.weight', 'base_model.model.layers.29.mlp.up_proj.weight', 'base_model.model.layers.29.mlp.down_proj.weight', 'base_model.model.layers.29.input_layernorm.weight', 'base_model.model.layers.29.post_attention_layernorm.weight', 'base_model.model.layers.30.self_attn.q_proj.weight', 'base_model.model.layers.30.self_attn.k_proj.weight', 'base_model.model.layers.30.self_attn.v_proj.weight', 'base_model.model.layers.30.self_attn.o_proj.weight', 'base_model.model.layers.30.mlp.gate_proj.weight', 'base_model.model.layers.30.mlp.up_proj.weight', 'base_model.model.layers.30.mlp.down_proj.weight', 'base_model.model.layers.30.input_layernorm.weight', 'base_model.model.layers.30.post_attention_layernorm.weight', 'base_model.model.layers.31.self_attn.q_proj.weight', 'base_model.model.layers.31.self_attn.k_proj.weight', 'base_model.model.layers.31.self_attn.v_proj.weight', 'base_model.model.layers.31.self_attn.o_proj.weight', 'base_model.model.layers.31.mlp.gate_proj.weight', 'base_model.model.layers.31.mlp.up_proj.weight', 'base_model.model.layers.31.mlp.down_proj.weight', 'base_model.model.layers.31.input_layernorm.weight', 'base_model.model.layers.31.post_attention_layernorm.weight', 'base_model.model.norm.weight', 'base_model.score.original_module.weight', 'word_embeddings.weight'], unexpected_keys=[])"},"metadata":{}}]},{"cell_type":"code","source":"val_data = InfData(test_df)\nval_loader = DataLoader(val_data, batch_size=batch_size, shuffle=False, \\\n                          collate_fn=partial(collate_inf,tokenizer=tokenizer))","metadata":{"execution":{"iopub.status.busy":"2023-11-10T19:03:32.510034Z","iopub.execute_input":"2023-11-10T19:03:32.510746Z","iopub.status.idle":"2023-11-10T19:03:32.515238Z","shell.execute_reply.started":"2023-11-10T19:03:32.510712Z","shell.execute_reply":"2023-11-10T19:03:32.514190Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"probs = []\nfor input_ids,attention_mask in val_loader:\n    input_ids,attention_mask = input_ids.to('cuda'),attention_mask.to('cuda')\n    with torch.no_grad():\n        out = model(input_ids=input_ids,attention_mask=attention_mask).logits[:,0].detach().cpu().numpy()\n    probs.append(out)\nprobs = np.concatenate(probs)","metadata":{"execution":{"iopub.status.busy":"2023-11-10T19:03:44.030794Z","iopub.execute_input":"2023-11-10T19:03:44.031422Z","iopub.status.idle":"2023-11-10T19:03:58.081037Z","shell.execute_reply.started":"2023-11-10T19:03:44.031391Z","shell.execute_reply":"2023-11-10T19:03:58.080270Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"sub = pd.DataFrame()\nsub['id'] = test_df['id']\nsub['generated'] = probs\nsub.to_csv('submission.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2023-11-10T19:04:18.127412Z","iopub.execute_input":"2023-11-10T19:04:18.127775Z","iopub.status.idle":"2023-11-10T19:04:18.149155Z","shell.execute_reply.started":"2023-11-10T19:04:18.127745Z","shell.execute_reply":"2023-11-10T19:04:18.148374Z"},"trusted":true},"execution_count":21,"outputs":[{"execution_count":21,"output_type":"execute_result","data":{"text/plain":"         id  generated\n0  0000aaaa  -1.176758\n1  1111bbbb  -3.904297\n2  2222cccc  -3.126953","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>generated</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0000aaaa</td>\n      <td>-1.176758</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1111bbbb</td>\n      <td>-3.904297</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2222cccc</td>\n      <td>-3.126953</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]}]}